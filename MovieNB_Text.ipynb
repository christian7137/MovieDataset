{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General imports here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import math\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import operator\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary CSV files\n",
    "keywords_df = pd.read_csv('./data/keywords.csv')\n",
    "metadata_df = pd.read_csv('./data/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45454\n",
      "45454\n",
      "done\n",
      "Starting Analysis\n"
     ]
    }
   ],
   "source": [
    "PREPROCESS = True # set this to use already processed text or to rerun processing\n",
    "\n",
    "def preprocess_text(full_word_data, file_name):\n",
    "    print len(overviews)\n",
    "    wordsFreq = defaultdict(int)\n",
    "\n",
    "    missing = 0\n",
    "    word_bank = []\n",
    "    for a_word in full_word_data:\n",
    "        try:\n",
    "            t = nltk.word_tokenize(a_word)\n",
    "        except:\n",
    "            missing += 1\n",
    "        word_bank += t\n",
    "        \n",
    "    # Preprocessing the text\n",
    "    # Remove new lines and convert all letters to lower\n",
    "    processed_word_bank = [string.replace(word_bank[i], '\\n', ' ') for i in range(len(word_bank))]\n",
    "    processed_word_bank = [u.lower() for u in processed_word_bank]\n",
    "\n",
    "    #remove punctuation\n",
    "    processed_word_bank = [''.join(c for c in doc if c not in string.punctuation) for doc in processed_word_bank]\n",
    "\n",
    "    #remove numbers\n",
    "    processed_word_bank = [re.sub(\"\\d+\", \" \", doc) for doc in processed_word_bank]\n",
    "\n",
    "    #trim whitespace\n",
    "    processed_word_bank = [re.sub( '\\s+', ' ', doc ).strip() for doc in processed_word_bank]\n",
    "\n",
    "    #remove empty strings\n",
    "    t = []\n",
    "    for word in processed_word_bank:\n",
    "        if word != '':\n",
    "            t.append(word)\n",
    "    processed_word_bank = t\n",
    "\n",
    "    # Write the preproccesed strings into a text file\n",
    "    txt = open(\"./data/\" + file_name + \".txt\", \"a\")\n",
    "    for word in processed_word_bank:\n",
    "        txt.write(word + \"\\n\")\n",
    "    txt.close()\n",
    "\n",
    "processed_word_bank = []\n",
    "if PREPROCESS == True:\n",
    "    \n",
    "    overviews = metadata_df['overview'][:45454]\n",
    "    titles = metadata_df['title'][:45454]\n",
    "    preprocess_text(overviews, \"overviews_processed\")\n",
    "    preprocess_text(titles, \"titles_processed\")\n",
    "    print \"done\"  \n",
    "else:\n",
    "    txt = open(\"./data/processed_words.txt\", \"r\")\n",
    "    processed_word_bank = nltk.word_tokenize(txt.read())\n",
    " \n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Text analysis\n",
    "# Perform simple wordcount\n",
    "\n",
    "# wordsFreq = defaultdict(int)\n",
    "# for word in processed_word_bank:\n",
    "#     wordsFreq[word] += 1\n",
    "\n",
    "# result = sorted(wordsFreq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# pprint.pprint(result, width=1)\n",
    "# print \"done\"\n",
    "print \"Starting Analysis\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
