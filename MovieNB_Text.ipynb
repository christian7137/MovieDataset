{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General imports here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import math\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import operator\n",
    "import pprint\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary CSV files\n",
    "keywords_df = pd.read_csv('./data/keywords.csv')\n",
    "metadata_df = pd.read_csv('./data/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gensim model creation\n",
      "model finished and saved\n",
      "172407\n",
      "27831\n",
      "done\n",
      "Starting Analysis\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "PREPROCESS = True # set this to use already processed text or to rerun processing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(full_word_data, file_name):\n",
    "    print len(overviews)\n",
    "    wordsFreq = defaultdict(int)\n",
    "\n",
    "    missing = 0\n",
    "    word_bank = []\n",
    "    for a_word in full_word_data:\n",
    "        try:\n",
    "            t = nltk.word_tokenize(a_word)\n",
    "        except:\n",
    "            missing += 1\n",
    "        word_bank += t\n",
    "        \n",
    "    # Preprocessing the text\n",
    "    # Remove new lines and convert all letters to lower\n",
    "    processed_word_bank = [string.replace(word_bank[i], '\\n', ' ') for i in range(len(word_bank))]\n",
    "    processed_word_bank = [u.lower() for u in processed_word_bank]\n",
    "\n",
    "    #remove punctuation\n",
    "    processed_word_bank = [''.join(c for c in doc if c not in string.punctuation) for doc in processed_word_bank]\n",
    "\n",
    "    #remove numbers\n",
    "    processed_word_bank = [re.sub(\"\\d+\", \" \", doc) for doc in processed_word_bank]\n",
    "\n",
    "    #trim whitespace\n",
    "    processed_word_bank = [re.sub( '\\s+', ' ', doc ).strip() for doc in processed_word_bank]\n",
    "\n",
    "    #remove empty strings\n",
    "    t = []\n",
    "    for word in processed_word_bank:\n",
    "        if word != '':\n",
    "            t.append(word)\n",
    "    processed_word_bank = t\n",
    "\n",
    "    # Write the preproccesed strings into a text file\n",
    "    txt = open(\"./data/\" + file_name + \".txt\", \"a\")\n",
    "    for word in processed_word_bank:\n",
    "        txt.write(word + \"\\n\")\n",
    "    txt.close()\n",
    "    \n",
    "    return wordsFreq\n",
    "\n",
    "processed_word_bank = []\n",
    "wordsFreq_0 = None\n",
    "wordsFreq_1 = None\n",
    "\n",
    "overview_samples = {}\n",
    "date_rel_samples = {}\n",
    "\n",
    "if PREPROCESS == True:\n",
    "    overviews = metadata_df['overview'][:45454]\n",
    "    titles = metadata_df['title'][:45454]\n",
    "    \n",
    "    overviews_list = []\n",
    "    titles_list = []\n",
    "    for a in overviews:\n",
    "        if isinstance(a, basestring):\n",
    "            b = a.split(\" \")\n",
    "            overviews_list.append(b)\n",
    "    for a in titles:\n",
    "        if isinstance(a, basestring):\n",
    "            b = a.split(\" \")\n",
    "            titles_list.append(b)\n",
    "\n",
    "#     for index, row in metadata_df.iterrows():\n",
    "#         overview_samples[row['id']] = row['overview']\n",
    "#         date_rel_samples[row['id']] = row['release_date']\n",
    "\n",
    "    print \"Starting gensim model creation\"\n",
    "    model = gensim.models.Word2Vec(overviews_list, min_count=1)\n",
    "    model0 = gensim.models.Word2Vec(titles_list, min_count=1)\n",
    "    model.save(\"./models/gs_mod_overviews\")\n",
    "    model0.save(\"./models/gs_mod_origtitle\")\n",
    "    print \"model finished and saved\"\n",
    "    print len(model.wv.vocab)\n",
    "    print len(model0.wv.vocab)\n",
    "\n",
    "    #for i in date_rel_samples\n",
    "    #print overview_samples\n",
    "    #print date_rel_samples\n",
    "    \n",
    "    #wordsFreq_0 = preprocess_text(overviews, \"overviews_processed\")\n",
    "    #wordsFreq_1 = preprocess_text(titles, \"titles_processed\")\n",
    "    print \"done\"  \n",
    "else:\n",
    "    txt = open(\"./data/processed_words.txt\", \"r\")\n",
    "    processed_word_bank = nltk.word_tokenize(txt.read())\n",
    " \n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Text analysis\n",
    "# Perform simple wordcount\n",
    "\n",
    "# wordsFreq = defaultdict(int)\n",
    "# for word in processed_word_bank:\n",
    "#     wordsFreq[word] += 1\n",
    "\n",
    "# result = sorted(wordsFreq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# pprint.pprint(result, width=1)\n",
    "# print \"done\"\n",
    "print \"Starting Analysis\"\n",
    "\n",
    "# overviews_result = sorted(wordsFreq_0.items(), key=operator.itemgetter(1), reverse=True)[0:10]\n",
    "# title_result = sorted(wordsFreq_1.items(), key=operator.itemgetter(1), reverse=True)[0:10]\n",
    "# print overviews_result\n",
    "# print title_result\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
